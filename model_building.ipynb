{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e9beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ecc18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>aspect</th>\n",
       "      <th>strdist</th>\n",
       "      <th>basarea</th>\n",
       "      <th>basin</th>\n",
       "      <th>curvature</th>\n",
       "      <th>curve_cont</th>\n",
       "      <th>curve_prof</th>\n",
       "      <th>curves</th>\n",
       "      <th>...</th>\n",
       "      <th>elev</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>slide</th>\n",
       "      <th>scarpdist</th>\n",
       "      <th>scarps</th>\n",
       "      <th>frictang</th>\n",
       "      <th>slope</th>\n",
       "      <th>slopeleg</th>\n",
       "      <th>woods</th>\n",
       "      <th>specwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>265.2971</td>\n",
       "      <td>644.9806</td>\n",
       "      <td>65600</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.156464</td>\n",
       "      <td>0.636057</td>\n",
       "      <td>-1.520407</td>\n",
       "      <td>0.214373</td>\n",
       "      <td>...</td>\n",
       "      <td>1057.005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>28.28427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>15.34650</td>\n",
       "      <td>2024.026</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>267.3936</td>\n",
       "      <td>647.7654</td>\n",
       "      <td>65600</td>\n",
       "      <td>1</td>\n",
       "      <td>2.616730</td>\n",
       "      <td>-2.301352</td>\n",
       "      <td>0.315377</td>\n",
       "      <td>0.135763</td>\n",
       "      <td>...</td>\n",
       "      <td>1065.420</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>12.92921</td>\n",
       "      <td>2015.106</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>272.0991</td>\n",
       "      <td>625.1400</td>\n",
       "      <td>65600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>-0.073801</td>\n",
       "      <td>-0.044779</td>\n",
       "      <td>0.164955</td>\n",
       "      <td>...</td>\n",
       "      <td>1058.138</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>16.34302</td>\n",
       "      <td>1985.669</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>272.9689</td>\n",
       "      <td>628.0128</td>\n",
       "      <td>65600</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.793457</td>\n",
       "      <td>0.881960</td>\n",
       "      <td>-0.911497</td>\n",
       "      <td>0.215654</td>\n",
       "      <td>...</td>\n",
       "      <td>1063.369</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>16.76664</td>\n",
       "      <td>1976.543</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>261.2346</td>\n",
       "      <td>631.5062</td>\n",
       "      <td>65600</td>\n",
       "      <td>1</td>\n",
       "      <td>2.723572</td>\n",
       "      <td>-2.240553</td>\n",
       "      <td>0.483019</td>\n",
       "      <td>0.142164</td>\n",
       "      <td>...</td>\n",
       "      <td>1072.220</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>13.31464</td>\n",
       "      <td>1968.201</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID    aspect   strdist  basarea  basin  curvature  curve_cont  \\\n",
       "0           2   3  265.2971  644.9806    65600      1  -2.156464    0.636057   \n",
       "1           3   4  267.3936  647.7654    65600      1   2.616730   -2.301352   \n",
       "2           6   7  272.0991  625.1400    65600      1   0.029022   -0.073801   \n",
       "3           7   8  272.9689  628.0128    65600      1  -1.793457    0.881960   \n",
       "4           8   9  261.2346  631.5062    65600      1   2.723572   -2.240553   \n",
       "\n",
       "   curve_prof    curves  ...      elev  cohesion  slide  scarpdist  scarps  \\\n",
       "0   -1.520407  0.214373  ...  1057.005        10      1   28.28427     0.0   \n",
       "1    0.315377  0.135763  ...  1065.420        10      1   20.00000     0.0   \n",
       "2   -0.044779  0.164955  ...  1058.138        10      1   20.00000     0.0   \n",
       "3   -0.911497  0.215654  ...  1063.369        10      1   20.00000     0.0   \n",
       "4    0.483019  0.142164  ...  1072.220        10      1   20.00000     0.0   \n",
       "\n",
       "   frictang     slope  slopeleg  woods  specwt  \n",
       "0        23  15.34650  2024.026      1      19  \n",
       "1        23  12.92921  2015.106      1      19  \n",
       "2        23  16.34302  1985.669      1      19  \n",
       "3        23  16.76664  1976.543      1      19  \n",
       "4        23  13.31464  1968.201      1      19  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "928156c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922dae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729cfeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aspect', 'strdist', 'basarea', 'basin', 'curvature', 'curve_cont',\n",
       "       'curve_prof', 'curves', 'drop', 'rockdist', 'flowdir', 'fos', 'lith',\n",
       "       'elev', 'cohesion', 'slide', 'scarpdist', 'scarps', 'frictang', 'slope',\n",
       "       'slopeleg', 'woods', 'specwt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06406e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da6b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = df.drop('slide', axis=1)\n",
    "y = df['slide']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4051109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ccae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model:\n",
      "Validation Accuracy: 0.9252\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      2048\n",
      "           1       0.88      0.90      0.89      1015\n",
      "\n",
      "    accuracy                           0.93      3063\n",
      "   macro avg       0.91      0.92      0.92      3063\n",
      "weighted avg       0.93      0.93      0.93      3063\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAKSHI\\anaconda3\\envs\\leaf_disease\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost Model:\n",
      "Validation Accuracy: 0.9252\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      2048\n",
      "           1       0.88      0.89      0.89      1015\n",
      "\n",
      "    accuracy                           0.93      3063\n",
      "   macro avg       0.92      0.92      0.92      3063\n",
      "weighted avg       0.93      0.93      0.93      3063\n",
      "\n",
      "==================================================\n",
      "Decision Tree Model:\n",
      "Validation Accuracy: 0.8897\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2048\n",
      "           1       0.83      0.83      0.83      1015\n",
      "\n",
      "    accuracy                           0.89      3063\n",
      "   macro avg       0.88      0.88      0.88      3063\n",
      "weighted avg       0.89      0.89      0.89      3063\n",
      "\n",
      "==================================================\n",
      "Logistic Regression Model:\n",
      "Validation Accuracy: 0.6709\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78      2048\n",
      "           1       0.51      0.28      0.36      1015\n",
      "\n",
      "    accuracy                           0.67      3063\n",
      "   macro avg       0.61      0.57      0.57      3063\n",
      "weighted avg       0.64      0.67      0.64      3063\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Evaluate model performance on validation set\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    classification_rep = classification_report(y_val, y_pred)\n",
    "\n",
    "    print(f\"{name} Model:\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_rep)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39486aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model (Test Set):\n",
      "Test Accuracy: 0.9305\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2020\n",
      "           1       0.90      0.90      0.90      1043\n",
      "\n",
      "    accuracy                           0.93      3063\n",
      "   macro avg       0.92      0.92      0.92      3063\n",
      "weighted avg       0.93      0.93      0.93      3063\n",
      "\n",
      "==================================================\n",
      "XGBoost Model (Test Set):\n",
      "Test Accuracy: 0.9321\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2020\n",
      "           1       0.90      0.90      0.90      1043\n",
      "\n",
      "    accuracy                           0.93      3063\n",
      "   macro avg       0.92      0.92      0.92      3063\n",
      "weighted avg       0.93      0.93      0.93      3063\n",
      "\n",
      "==================================================\n",
      "Decision Tree Model (Test Set):\n",
      "Test Accuracy: 0.8867\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      2020\n",
      "           1       0.84      0.83      0.83      1043\n",
      "\n",
      "    accuracy                           0.89      3063\n",
      "   macro avg       0.87      0.87      0.87      3063\n",
      "weighted avg       0.89      0.89      0.89      3063\n",
      "\n",
      "==================================================\n",
      "Logistic Regression Model (Test Set):\n",
      "Test Accuracy: 0.6676\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78      2020\n",
      "           1       0.52      0.26      0.35      1043\n",
      "\n",
      "    accuracy                           0.67      3063\n",
      "   macro avg       0.61      0.57      0.56      3063\n",
      "weighted avg       0.64      0.67      0.63      3063\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models on the test set\n",
    "for name, model in models.items():\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance on test set\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    classification_rep_test = classification_report(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"{name} Model (Test Set):\")\n",
    "    print(f\"Test Accuracy: {accuracy_test:.4f}\")\n",
    "    print(\"Test Classification Report:\")\n",
    "    print(classification_rep_test)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7734a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAKSHI\\anaconda3\\envs\\leaf_disease\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model (Test Set):\n",
      "Test Accuracy: 0.9321\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2020\n",
      "           1       0.90      0.90      0.90      1043\n",
      "\n",
      "    accuracy                           0.93      3063\n",
      "   macro avg       0.92      0.92      0.92      3063\n",
      "weighted avg       0.93      0.93      0.93      3063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model as a pickle file\n",
    "with open('xgb_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(xgb_model, model_file)\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open('xgb_model.pkl', 'rb') as model_file:\n",
    "    loaded_xgb_model = pickle.load(model_file)\n",
    "\n",
    "# Predict on the test data using the loaded model\n",
    "y_pred_test_xgb = loaded_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance on the test set\n",
    "accuracy_test_xgb = accuracy_score(y_test, y_pred_test_xgb)\n",
    "classification_rep_test_xgb = classification_report(y_test, y_pred_test_xgb)\n",
    "\n",
    "print(\"XGBoost Model (Test Set):\")\n",
    "print(f\"Test Accuracy: {accuracy_test_xgb:.4f}\")\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_rep_test_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24317168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAKSHI\\anaconda3\\envs\\leaf_disease\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model (Test Set):\n",
      "Test Accuracy: 0.9321\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      2020\n",
      "           1       0.90      0.90      0.90      1043\n",
      "\n",
      "    accuracy                           0.93      3063\n",
      "   macro avg       0.92      0.92      0.92      3063\n",
      "weighted avg       0.93      0.93      0.93      3063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model as a pickle file\n",
    "with open('xgb_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(xgb_model, model_file)\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open('xgb_model.pkl', 'rb') as model_file:\n",
    "    loaded_xgb_model = pickle.load(model_file)\n",
    "\n",
    "# Predict on the test data using the loaded model\n",
    "y_pred_test_xgb = loaded_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance on the test set\n",
    "accuracy_test_xgb = accuracy_score(y_test, y_pred_test_xgb)\n",
    "classification_rep_test_xgb = classification_report(y_test, y_pred_test_xgb)\n",
    "\n",
    "print(\"XGBoost Model (Test Set):\")\n",
    "print(f\"Test Accuracy: {accuracy_test_xgb:.4f}\")\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_rep_test_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc1dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adbee77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57aee812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open('xgb_model.pkl', 'rb') as model_file:\n",
    "    loaded_xgb_model = pickle.load(model_file)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def yield_fn(features_list):\n",
    "                int_features2 = np.array(features_list)\n",
    "\n",
    "                int_features1 = int_features2.reshape(1, -1)\n",
    "\n",
    "\n",
    "                tested1=loaded_xgb_model.predict(int_features1)\n",
    "\n",
    "\n",
    "\n",
    "                print(tested1)\n",
    "\n",
    "                return  tested1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc06ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_fn([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa41a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaccce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_disease",
   "language": "python",
   "name": "leaf_disease"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
